---
sidebar: sidebar
permalink: release-notes/known-issues.html
keywords: astra, control center, bugs, known issues, problems
summary: Known issues identify problems that might prevent you from using this release of the product successfully.
---

= Known issues
:source-highlighter: highlight.js
:hardbreaks:
:icons: font
:imagesdir: ../media/release-notes/

Known issues identify problems that might prevent you from using this release of the product successfully.

The following known issues affect the current release:

.Apps
* <<During app restore from backup Trident creates a larger PV than the original PV>>
* <<Clone performance impacted by large persistent volumes>>
* <<App clones fail using a specific version of PostgreSQL>>
* <<App clones fail when using Service Account level OCP Security Context Constraints (SCC)>>
* <<App clones fail after an application is deployed with a set storage class>>

.Clusters
* <<Managing a cluster with Astra Control Center fails when default kubeconfig file contains more than one context>>

.Other issues
* <<App data management operations fail with Internal Service Error (500) when Trident is offline>>
* link:known-issues.html#cant-determine-asup-tar-bundle-status-in-scaled-environment[Can't determine ASUP tar bundle status in scaled environment]
* <<Snapshots might fail with snapshot controller version 4.2.0>>

== During app restore from backup Trident creates a larger PV than the original PV
//DOC-3562/ASTRACTL-9560/Q2 and PI4
If you resize a persistent volume after creating a backup and then restore from that backup, the persistent volume size will match the new size of the PV instead of using the size of the backup.

== Clone performance impacted by large persistent volumes
//from ACS repo
Clones of very large and consumed persistent volumes might be intermittently slow, dependent on cluster access to the object store. If the clone is hung and no data has been copied for more than 30 minutes, Astra Control terminates the clone action.

== App clones fail using a specific version of PostgreSQL
//DOC-3543/ASTRACTL-9408/Q2 and PI4
App clones within the same cluster consistently fail with the Bitnami PostgreSQL 11.5.0 chart. To clone successfully, use an earlier or later version of the chart.

== App clones fail when using Service Account level OCP Security Context Constraints (SCC)
//ASTRACTL-10060/DOC-3594/Q2 and PI4
An application clone might fail if the original security context constraints are configured at the service account level within the namespace on the OCP cluster. When the application clone fails, it appears in the Managed Applications area in Astra Control Center with status `Removed`. See the https://kb.netapp.com/Advice_and_Troubleshooting/Cloud_Services/Astra/Application_clone_is_failing_for_an_application_in_Astra_Control_Center[knowledgebase article] for more information.

== App clones fail after an application is deployed with a set storage class
//DOC-3892/ASTRACTL-13183/PI4/astractl-13184?
After an application is deployed with a storage class explicitly set (for example, `helm install ...-set global.storageClass=netapp-cvs-perf-extreme`), subsequent attempts to clone the application require that the target cluster have the originally specified storage class.
Cloning an application with an explicitly set storage class to a cluster that does not have the same storage class will fail. There are no recovery steps in this scenario.

== Managing a cluster with Astra Control Center fails when default kubeconfig file contains more than one context
//ASTRACTL-8872/DOC-3612/Q2 and PI4
You cannot use a kubeconfig with more than one cluster and context in it. See the link:https://kb.netapp.com/Advice_and_Troubleshooting/Cloud_Services/Astra/Managing_cluster_with_Astra_Control_Center_may_fail_when_using_default_kubeconfig_file_contains_more_than_one_context[knowledgebase article] for more information.

== App data management operations fail with Internal Service Error (500) when Trident is offline
//DOC-3903/ASTRA-13162/PI4
If Trident on an app cluster goes offline (and is brought back online) and 500 internal service errors are encountered when attempting app data management, restart all of the Kubernetes nodes in the app cluster to restore functionality.

== Can't determine ASUP tar bundle status in scaled environment
//DOC-3602/ASTRACTL-10186/AD AH/Q2 and PI4
During ASUP collection, the status of the bundle in the UI is reported as either `collecting` or `done`. Collection can take up to an hour for large environments. During ASUP download, the network file transfer speed for the bundle might be insufficient, and the download might time out after 15 minutes without any indication in the UI. Download issues depend on the size of the ASUP, the scaled cluster size, and if collection time goes beyond the seven-day limit.

== Snapshots might fail with snapshot controller version 4.2.0
//DOC-3891 and ASTRACTL-12523
When you use Kubernetes snapshot-controller (also known as external-snapshotter) version 4.2.0 with Kubernetes 1.20 or 1.21, snapshots can eventually begin to fail. To prevent this, use a different https://kubernetes-csi.github.io/docs/snapshot-controller.html[supported version^] of external-snapshotter, such as version 4.2.1, with Kubernetes versions 1.20 or 1.21.

== Find more information

* link:../release-notes/known-issues-ads.html[Known issues with Astra Data Store prreview and this Astra Control Center release]
* link:../release-notes/known-limitations.html[Known limitations]
